{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas necessárias:\n",
    "* beautifulsoup4\n",
    "* lxml   \n",
    "* pandas\n",
    "* pdfplumber\n",
    "* requests\n",
    "* PyPDF2\n",
    "* re\n",
    "\n",
    "## Instalação\n",
    "```sh \n",
    "pip3 install lxml beautifulsoup4 requests pandas pdfplumber\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://spreadsheets.google.com/feeds/list/1IJBDu8dRGLkBgX72sRWKY6R9GfefsaDCXBd3Dz9PZNs/14/public/values'\n",
    "nome = 'GRACIANA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pasta_de_download\n",
    "except:\n",
    "    pasta_de_download = './arquivos_baixados'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar lista contendo todos os endereços dos arquivos PDF para download listados no endereço da variável url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_lista_de_pdf(url):\n",
    "    pdf_doc = requests.get(url).text\n",
    "    soup = BeautifulSoup(pdf_doc, 'xml')\n",
    "    lista_de_pdf = [ item.pdf.text for item in soup.find_all('entry') ]\n",
    "    return lista_de_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixar os arquivos somente se já não existirem localmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_pasta_de_download(pasta_de_download):\n",
    "    try:\n",
    "        if not os.path.isdir(pasta_de_download):\n",
    "            os.mkdir(pasta_de_download) \n",
    "    except OSError:\n",
    "        print (\"Criação do diretório de download falhou %s \" % pasta_de_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_arquivo(url,pasta_de_download='.'):\n",
    "    nome_do_arquivo = url.rsplit('/', 1)[-1]\n",
    "    caminho = os.path.join(pasta_de_download, nome_do_arquivo)\n",
    "    try:\n",
    "        if not os.path.isfile(caminho):\n",
    "            wget.download(url, out=caminho)\n",
    "    except:\n",
    "        print(\"Não foi possível salvar o arquivo {}\".format(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_arquivo(url,pasta_de_download='.'):\n",
    "    nome_do_arquivo = url.rsplit('/', 1)[-1]\n",
    "    caminho = os.path.join(pasta_de_download, nome_do_arquivo)\n",
    "    try:\n",
    "        if not os.path.isfile(caminho):\n",
    "            arquivo_stream = requests.get(url, stream=True)\n",
    "            with open(caminho, 'wb') as local_file:\n",
    "                for data in arquivo_stream:\n",
    "                    local_file.write(data)\n",
    "    except:\n",
    "        print('Não foi possível salvar o arquivo na url {}'.format(url))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procura_nome_pdfgrep(nome, pasta='.'):\n",
    "    resultado_da_busca = subprocess.getoutput('pdfgrep -i \"{}\" {}/*.pdf'.format(nome, pasta))\n",
    "    return resultado_da_busca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_pasta_de_download(pasta_de_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista_de_links=scrape_lista_de_pdf(url)\n",
    "for link in lista_de_links:\n",
    "    download_arquivo(link, pasta_de_download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busca usando pdfgrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procurando agendamento de \"GRACIANA\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./arquivos_baixados/Drive-Riomar-Kennedy-27.02.2021.pdf:        NELI GRACIANA DE JESUS            DIONISIO TORRES       SHOPPING RIOMAR KENNEDY2021-02-27   13:00:00\\npdfgrep: Could not open ./arquivos_baixados/LISTA%20DRIVE%20CASTEL%C3%83O%2008022021.pdf\\npdfgrep: Could not open ./arquivos_baixados/LISTA%20DRIVE%20CENTRO%20DE%20EVENTOS%2008022021.pdf'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Procurando agendamento de \"{}\"'.format(nome))\n",
    "procura_nome_pdfgrep(nome, pasta_de_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
